{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUfB11RSeqc1"
   },
   "source": [
    "<img src=\"https://relevance.ai/wp-content/uploads/2021/11/logo.79f303e-1.svg\" width=\"150\" alt=\"Relevance AI\" />\n",
    "<h5> Developer-first vector platform for ML teams </h5>\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RelevanceAI/workflows/blob/main/workflows/vectorize/Vectorize_Your_Data_with_Relevance_AI_form.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjROUZqQbiGq"
   },
   "outputs": [],
   "source": [
    "#@title After filling this form, press the top left button.\n",
    "# You can grab your token here https://cloud.relevance.ai/sdk/api\n",
    "\n",
    "token = \"<copy paste from https://cloud.relevance.ai/sdk/api>\"  #@param  {type:\"string\"}\n",
    "dataset_id = \"<your dataset ID here>\"  #@param {type:\"string\"}\n",
    "encode_type = \"<choose from text|image_urls>\"  #@param {type: \"integer\"}\n",
    "model_id = \"<choose from mpnet|multiqampnet|bit|clip or sentence-transformers/<model_url> from https://huggingface.co/sentence-transformers>\"  #@param {type:\"string\"}\n",
    "fields =  \"<your fields to vectorize here eg. product_title, product_description>\"    #@param {type:\"string\"}\n",
    "\n",
    "project = token.split(':')[0]\n",
    "api_key = token.split(':')[1]\n",
    "region = token.split(':')[2]\n",
    "\n",
    "\n",
    "def strip_empty_string(list):\n",
    "    without_empty_strings = []\n",
    "    for string in list:\n",
    "        if (string != ''):\n",
    "            without_empty_strings.append(string.strip())\n",
    "    return without_empty_strings\n",
    "\n",
    "fields = strip_empty_string(fields.split(','))\n",
    "\n",
    "### Field Validation ###\n",
    "\n",
    "if encode_type not in ['text', 'image_urls']:\n",
    "    print(f'Encode type {encode_type} is not supported. Choose from text or image_urls.')\n",
    "\n",
    "if (model_id not in ['mpnet', 'multiqampnet', 'bit', 'clip']) or ('sentence-transformers/' not in model_id):\n",
    "    print(f'Model ID {model_id} is not supported. Choose from mpnet, multiqampnet, bit, clip or sentence-transformers/<model_url> from https://huggingface.co/sentence-transformers.')\n",
    "\n",
    "!pip install -q RelevanceAI==2.3.2\n",
    "\n",
    "from relevanceai import Client \n",
    "client = Client(token=token)\n",
    "\n",
    "ds = client.Dataset(dataset_id)\n",
    "\n",
    "\n",
    "if (fields not in ['mpnet', 'multiqampnet', 'bit', 'clip']) or ('sentence-transformers/' not in model_id):\n",
    "    print(f'Model ID {model_id} is not supported. Choose from mpnet, multiqampnet, bit, clip or sentence-transformers/<model_url> from https://huggingface.co/sentence-transformers.')\n",
    "\n",
    "config = {\n",
    "    \"dataset_id\": dataset_id,\n",
    "    \"model_id\": model_id,\n",
    "    \"encode_type\": encode_type,\n",
    "    \"fields\": fields,\n",
    "    \"region\": region,\n",
    "    \"project\": project,\n",
    "    \"api_key\": api_key,\n",
    "    \"authorizationToken\": token\n",
    "}\n",
    "\n",
    "project = token.split(':')[0]\n",
    "api_key = token.split(':')[1]\n",
    "region = token.split(':')[2]\n",
    "\n",
    "show_warnings_in_logs = False #@param {type:\"boolean\"}\n",
    "#@markdown Once the form is filled and you've clicked run, monitor below for logs of it running\n",
    "\n",
    "import base64\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Installing RelevanceAI ...\")\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        process = subprocess.Popen(['pip', 'install', package],\n",
    "                            stdout=subprocess.PIPE, \n",
    "                            stderr=subprocess.PIPE)\n",
    "        stdout, stderr = process.communicate()\n",
    "    except:\n",
    "        raise ValueError(f'Error installing {package}. {stdout} {stderr}')\n",
    "\n",
    "print(\"Installing machine learning models and dependencies to vectorize data. Takes ~2mins.\")\n",
    "\n",
    "import contextlib\n",
    "\n",
    "class DevNull:\n",
    "    def write(self, msg):\n",
    "        pass\n",
    "\n",
    "try:\n",
    "    if config['model_id'] == 'clip' and config['encode_type'].lower() == 'image_urls':\n",
    "        install_package(\"vectorhub[clip]\")\n",
    "        from vectorhub.bi_encoders.text_image.torch import Clip2Vec\n",
    "        class Model(Clip2Vec):\n",
    "            @property\n",
    "            def __name__(self):\n",
    "                return config['model_id']\n",
    "        enc = Model()\n",
    "        enc.encode = enc.encode_image\n",
    "\n",
    "    elif config['model_id'] == 'clip' and config['encode_type'].lower() == 'text':\n",
    "        install_package(\"vectorhub[clip]\")\n",
    "        from vectorhub.bi_encoders.text_image.torch import Clip2Vec\n",
    "        class Model(Clip2Vec):\n",
    "            @property\n",
    "            def __name__(self):\n",
    "                return config['model_id']\n",
    "        enc = Model()\n",
    "        enc.encode = enc.encode_text\n",
    "\n",
    "    elif config['model_id'] == 'mpnet':\n",
    "        install_package(\"vectorhub[encoders-text-sentence-transformers]\")\n",
    "        from vectorhub.encoders.text.sentence_transformers import SentenceTransformer2Vec\n",
    "        class Model(SentenceTransformer2Vec):\n",
    "            @property\n",
    "            def __name__(self):\n",
    "                return config['model_id']\n",
    "        enc = Model(\"all-mpnet-base-v2\")\n",
    "\n",
    "    elif config['model_id'] == 'multiqampnet':\n",
    "        install_package(\"vectorhub[encoders-text-sentence-transformers]\")\n",
    "        from vectorhub.encoders.text.sentence_transformers  import SentenceTransformer2Vec\n",
    "        class Model(SentenceTransformer2Vec):\n",
    "            @property\n",
    "            def __name__(self):\n",
    "                return config['model_id']\n",
    "        enc = Model(\"multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "    elif config['model_id'] == 'bit':\n",
    "        install_package(\"vectorhub[encoders-image-tfhub]\")\n",
    "        from vectorhub.encoders.image.tfhub import BitMedium2Vec\n",
    "        class Model(BitMedium2Vec):\n",
    "            @property\n",
    "            def __name__(self):\n",
    "                return config['model_id']\n",
    "        enc = Model()\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    raise ValueError(f'Incorrect token provided. {json.dumps(config, indent=2)}')\n",
    "\n",
    "print(\"Finished installing machine learning models and dependencies to vectorize data.\")\n",
    "# enc.__name__ = config['model_id']\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "f = open(os.devnull, 'w')\n",
    "sys.stderr = f\n",
    "\n",
    "def encode_documents(docs):\n",
    "    try:\n",
    "      if show_warnings_in_logs:\n",
    "          with contextlib.redirect_stdout(None):\n",
    "              with warnings.catch_warnings():\n",
    "                  warnings.simplefilter(\"ignore\")\n",
    "                  return enc.encode_documents(config['fields'], docs)\n",
    "      return enc.encode_documents(config['fields'], docs)\n",
    "    except:\n",
    "      raise Exception(\"===TRY RESTARTING COLAB NOTEBOOK! Click 'Runtime' > 'Restart runtime'===\")\n",
    "\n",
    "print(\"Starting to vectorize your data.\")\n",
    "# Simple bug fix lol\n",
    "client.logger.warn = client.logger.warning\n",
    "client.pull_update_push(config['dataset_id'], encode_documents, \n",
    "  show_progress_bar=True, \n",
    "  filters=[{'field' : f,\n",
    "    'filter_type' : 'exists', \n",
    "    \"condition\":\"==\", \n",
    "    \"condition_value\":\"\"} for f in config['fields']], \n",
    "    select_fields=config['fields'], retrieve_chunk_size=100)\n",
    "\n",
    "print(\"Finished vectorizing your data with, you may close this window.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MRy5bYU_1OV4"
   },
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Vectorize Your Data with Relevance AI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "name": "Vectorize_Your_Data_with_Relevance_AI"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
