{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RelevanceAI/workflows/blob/main/workflows/cluster/Cluster_Your_Data_with_Relevance_AI.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUfB11RSeqc1"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "1. Paste the token copied to your clipboard provided from the 'Cluster' Workflow dashboard.\n",
        "2. Click the ▶️  on the left or go to \"Runtime\" -> \"Run All\" and click \"Run anyway\" on the warning that pops up.\n",
        "3. You should see a progress bar underneath the form, keep this window opened and active until the progress bar is complete otherwise it'll terminate.\n",
        "\n",
        "Note: \n",
        "- For fastest clustering speed make sure to go to \"Runtime\" -> \"Change runtime type\" and enable \"Hardware accelerator\" as \"GPU\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TjROUZqQbiGq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'dataset_id': 'clothes', 'n_clusters': 10, 'vector_fields': ['image_path_clip_vector_'], 'region': 'us-east-1', 'project': '334fe5fb667b3a64dada', 'api_key': 'WWtHUXJYNEJoeGxuNEFNVXQtN186c21SZWVFaklSbGVKWjh2TmtyU2dRZw'}\n",
            "Installing RelevanceAI\n",
            "Fitting dataset...\n",
            "Updating your dataset...\n"
          ]
        }
      ],
      "source": [
        "#@title Paste token below and press ▶️  button to the left of this title { display-mode: \"form\" }\n",
        "# %tb\n",
        "\n",
        "token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "show_warnings_in_logs = False #@param {type:\"boolean\"}\n",
        "#@markdown Once the form is filled and you've clicked run, monitor below for logs of it running\n",
        "\n",
        "import base64\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "config = json.loads(base64.b64decode(token + \"===\"))\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def install_package(package):\n",
        "    process = subprocess.Popen(['pip', 'install', package],\n",
        "                        stdout=subprocess.PIPE, \n",
        "                        stderr=subprocess.PIPE)\n",
        "    stdout, stderr = process.communicate()\n",
        "    return\n",
        "print(config)\n",
        "\n",
        "!pip install -q RelevanceAI==0.33.2 --quiet\n",
        "print(\"Installing RelevanceAI\")\n",
        "\n",
        "import contextlib\n",
        "\n",
        "class DevNull:\n",
        "    def write(self, msg):\n",
        "        pass\n",
        "\n",
        "\n",
        "## Instantiate client ###\n",
        "from relevanceai import Client \n",
        "if config['region'] != 'old-australia-east':\n",
        "  region = config['region']\n",
        "  base_url = f\"https://api.{region}.relevance.ai/latest/\"\n",
        "  client = Client(config['project'], config['api_key'])\n",
        "  client.base_url = base_url\n",
        "  client.ingest_base_url = base_url\n",
        "  client.config['api.base_url'] = client.base_url\n",
        "  client.config['api.base_ingest_url'] = client.base_url\n",
        "else:\n",
        "  client = Client(config['project'], config['api_key'])\n",
        "\n",
        "## Checking valid vector field ###\n",
        "for v in config['vector_fields']:\n",
        "  if not '_vector_'in v:\n",
        "    raise ValueError(f\"'{v}' is not a valid vector field\")\n",
        "\n",
        "\n",
        "## Instantiate client ###\n",
        "try:\n",
        "\n",
        "  dataset_id = config['dataset_id']\n",
        "  df = client.Dataset(dataset_id)\n",
        "  \n",
        "  cluster_method = 'kmeans'\n",
        "  if df.shape[0] > 3000:\n",
        "    cluster_method = 'minibatchkmeans'\n",
        "\n",
        "  clusterer = df.auto_cluster(f\"{cluster_method}-{config['n_clusters']}\", vector_fields=config['vector_fields'])\n",
        "\n",
        "except Exception as e:\n",
        "    raise ValueError('Incorrect token provided')\n",
        "\n",
        "\n",
        "print(\"Finished clustering your data, you may close this window.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Cluster Your Data with Relevance AI.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "ce74dd10116053770a9f879f012eff522217714348206cf6ee41fb944aa63a70"
    },
    "kernelspec": {
      "display_name": "Python 3.7.10 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
