{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24gb3YFYTLkt"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RelevanceAI/workflows/blob/main/workflows/cluster/Cluster_Your_Data_with_Relevance_AI.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUfB11RSeqc1"
   },
   "source": [
    "# Instructions\n",
    "\n",
    "1. Paste the token copied to your clipboard provided from the 'Subcluster' Workflow dashboard.\n",
    "2. Click the ▶️  on the left or go to \"Runtime\" -> \"Run All\" and click \"Run anyway\" on the warning that pops up.\n",
    "3. You should see a progress bar underneath the form, keep this window opened and active until the progress bar is complete otherwise it'll terminate.\n",
    "\n",
    "Note: \n",
    "- For fastest clustering speed make sure to go to \"Runtime\" -> \"Change runtime type\" and enable \"Hardware accelerator\" as \"GPU\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjROUZqQbiGq"
   },
   "outputs": [],
   "source": [
    "#@title Paste token below and press ▶️  button to the left of this title { display-mode: \"form\" }\n",
    "# %tb\n",
    "\n",
    "# config = {\n",
    "#   \"dataset_id\": \"advanced_search_example\",\n",
    "#   \"n_clusters\": 10,\n",
    "#   \"vector_fields\": [\n",
    "#     \"product_title_clip_vector_\"\n",
    "#   ],\n",
    "#   \"cutoff\": 0.75,\n",
    "#   \"clusteringType\": \"community-detection\",\n",
    "#   \"region\": \"ap-southeast-2\",\n",
    "#   \"project\": \"xxx\",\n",
    "#   \"api_key\": \"xxx\",\n",
    "#   \"authorizationToken\": \"xxx:xxx:ap-southeast-2:xxx\"\n",
    "# }\n",
    "\n",
    "import base64\n",
    "import json\n",
    "\n",
    "token = \"\" #@param {type:\"string\"}\n",
    "\n",
    "show_warnings_in_logs = False #@param {type:\"boolean\"}\n",
    "#@markdown Once the form is filled and you've clicked run, monitor below for logs of it running\n",
    "\n",
    "config = json.loads(base64.b64decode(token + \"===\"))\n",
    "\n",
    "# print(json.dumps(config, indent=2))\n",
    "\n",
    "print(\"Installing RelevanceAI\")\n",
    "\n",
    "!pip install -q -U RelevanceAI==3.0.4\n",
    "## Instantiate client ###\n",
    "from relevanceai import Client \n",
    "client = Client(token=config['authorizationToken'])\n",
    "\n",
    "vector_fields = config['vector_fields']\n",
    "if isinstance(vector_fields, str):\n",
    "    vector_fields = [vector_fields]\n",
    "    \n",
    "## Checking valid vector field ###\n",
    "for v in vector_fields:\n",
    "  if not '_vector_'in v:\n",
    "    raise ValueError(f\"'{v}' is not a valid vector field\")\n",
    "\n",
    "\n",
    "df = client.Dataset(config['dataset_id'])\n",
    "cluster_method = \"kmeans\" # setting to default\n",
    "n_clusters = int(config.get('n_clusters', 25))\n",
    "try:\n",
    "  if config['clusteringType'] == 'community-detection':\n",
    "    cluster_method  = \"community_detection\"\n",
    "    !pip install -q sentence-transformers==2.2.0\n",
    "    df.cluster(\n",
    "        model=cluster_method,\n",
    "        model_kwargs={\"threshold\": config['cutoff']},\n",
    "        vector_fields=config['vector_fields']\n",
    "    )\n",
    "  elif config['clusteringType'] == 'kmeans':\n",
    "    if df.shape[0] < 10000:\n",
    "      from sklearn.cluster import KMeans\n",
    "      cluster_method = 'kmeans'\n",
    "      model = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "      alias = f\"{cluster_method}-{n_clusters}\"\n",
    "      df.cluster(\n",
    "          model=model,\n",
    "          model_kwargs={\"n_clusters\": n_clusters},\n",
    "          vector_fields=config['vector_fields'],\n",
    "          alias=alias\n",
    "      )\n",
    "    else:\n",
    "      cluster_method = 'minibatchkmeans'\n",
    "      from sklearn.cluster import MiniBatchKMeans\n",
    "      cluster_method = 'kmeans'\n",
    "      model = MiniBatchKMeans(n_clusters=n_clusters,random_state=42)\n",
    "      alias = f\"{cluster_method}-{n_clusters}\"\n",
    "\n",
    "      # Ensure chunksize is larger than number of clusters or else algorithm error\n",
    "      chunksize = n_clusters + 100\n",
    "      df.batch_cluster(\n",
    "          model=model,\n",
    "          model_kwargs={\"n_clusters\": n_clusters},\n",
    "          vector_fields=config['vector_fields'],\n",
    "          alias=alias,\n",
    "          chunksize=chunksize\n",
    "      )\n",
    "  elif config['clusteringType'] == 'kmedoids':\n",
    "    !pip install -q scikit-learn-extra==0.2.0\n",
    "    from sklearn_extra.cluster import KMedoids\n",
    "    cluster_method = \"kmedoids\"\n",
    "    model = KMedoids(n_clusters=n_clusters, random_state=42, init=\"k-medoids++\")\n",
    "    alias = f\"{cluster_method}-{n_clusters}\"\n",
    "    df.cluster(\n",
    "        model=model,\n",
    "        model_kwargs={\"n_clusters\": n_clusters},\n",
    "        vector_fields=config['vector_fields'],\n",
    "        alias=alias\n",
    "    )\n",
    "  else:\n",
    "    cluster_method = \"kmeans\"\n",
    "    df.cluster(\n",
    "        model=cluster_method,\n",
    "        model_kwargs={\"n_clusters\": n_clusters, \"random_state\": 42},\n",
    "        vector_fields=config['vector_fields'],\n",
    "    )\n",
    "except Exception as e:\n",
    "  raise ValueError('Incorrect token provided')\n",
    "\n",
    "if cluster_method == \"community-detection\":\n",
    "    print(f\"Finished clustering your data with {cluster_method} with cutoff={config['cutoff']}, you may close this window.\")\n",
    "elif cluster_method == \"kmeans\":\n",
    "    print(f\"Finished clustering your data with {cluster_method} with n_clusters={n_clusters}, you may close this window.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Cluster Your Data with Relevance AI.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "interpreter": {
   "hash": "2f37d18d48c838ed4650d00746e8f1f7ae7217fa17e107ee8294938c0787d93b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "name": "Cluster_Your_Data_with_Relevance_AI",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
