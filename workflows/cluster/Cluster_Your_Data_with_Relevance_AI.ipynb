{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Cluster Your Data with Relevance AI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUfB11RSeqc1"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "1. Paste the token copied to your clipboard provided from the 'Cluster' Workflow dashboard.\n",
        "2. Click the ▶️  on the left or go to \"Runtime\" -> \"Run All\" and click \"Run anyway\" on the warning that pops up.\n",
        "3. You should see a progress bar underneath the form, keep this window opened and active until the progress bar is complete otherwise it'll terminate.\n",
        "\n",
        "Note: \n",
        "- For fastest clustering speed make sure to go to \"Runtime\" -> \"Change runtime type\" and enable \"Hardware accelerator\" as \"GPU\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjROUZqQbiGq"
      },
      "source": [
        "#@title Paste token below and press ▶️  button to the left of this title { display-mode: \"form\" }\n",
        "# %tb\n",
        "\n",
        "token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "show_warnings_in_logs = False #@param {type:\"boolean\"}\n",
        "#@markdown Once the form is filled and you've clicked run, monitor below for logs of it running\n",
        "\n",
        "import base64\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "config = json.loads(base64.b64decode(token + \"===\"))\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def install_package(package):\n",
        "    process = subprocess.Popen(['pip', 'install', package],\n",
        "                        stdout=subprocess.PIPE, \n",
        "                        stderr=subprocess.PIPE)\n",
        "    stdout, stderr = process.communicate()\n",
        "    return\n",
        "print(config)\n",
        "\n",
        "!pip install -q RelevanceAI==0.33.2 --quiet\n",
        "print(\"Installing RelevanceAI\")\n",
        "\n",
        "import contextlib\n",
        "\n",
        "class DevNull:\n",
        "    def write(self, msg):\n",
        "        pass\n",
        "\n",
        "\n",
        "## Instantiate client ###\n",
        "from relevanceai import Client \n",
        "if config['region'] != 'old-australia-east':\n",
        "  region = config['region']\n",
        "  base_url = f\"https://api.{region}.relevance.ai/latest/\"\n",
        "  client = Client(config['project'], config['api_key'])\n",
        "  client.base_url = base_url\n",
        "  client.ingest_base_url = base_url\n",
        "  client.config['api.base_url'] = client.base_url\n",
        "  client.config['api.base_ingest_url'] = client.base_url\n",
        "else:\n",
        "  client = Client(config['project'], config['api_key'])\n",
        "\n",
        "## Checking valid vector field ###\n",
        "for v in config['vector_fields']:\n",
        "  if not '_vector_'in v:\n",
        "    raise ValueError(f\"'{v}' is not a valid vector field\")\n",
        "\n",
        "\n",
        "## Instantiate client ###\n",
        "try:\n",
        "\n",
        "  dataset_id = config['dataset_id']\n",
        "  df = client.Dataset(dataset_id)\n",
        "  \n",
        "  cluster_method = 'kmeans'\n",
        "  if df.shape[0] > 3000:\n",
        "    cluster_method = 'minibatchkmeans'\n",
        "\n",
        "  clusterer = df.auto_cluster(f\"{cluster_method}-{config['n_clusters']}\", vector_fields=config['vector_fields'])\n",
        "\n",
        "except Exception as e:\n",
        "    raise ValueError('Incorrect token provided')\n",
        "\n",
        "\n",
        "print(\"Finished clustering your data, you may close this window.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}